import tkinter as tk
from tkinter import ttk
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tkinter_components.tkinter_info_buttom import *

class ProcessFrameBase:
    def __init__(self, frame):
        self.frame = frame
        self.create_widgets()
    
    def apply(self, img):
        raise NotImplementedError("apply method must be implemented in subclass.")

class ThresholdingFrame(ProcessFrameBase):
    name = "Thresholding"
    info_text = (
    "ğŸ“Œ Threshold Bilgisi\n\n"
    "â€¢ Threshold: 0 ile 255 arasÄ±nda bir deÄŸerdir. Bu eÅŸik deÄŸeri, gÃ¶rÃ¼ntÃ¼deki piksellerin ikili hale getirilmesinde kullanÄ±lÄ±r.\n\n"
    "â€¢ Threshold Type:\n"
    "  - Binary: Piksel deÄŸeri eÅŸikten bÃ¼yÃ¼kse 255 (beyaz), kÃ¼Ã§Ã¼kse 0 (siyah) yapÄ±lÄ±r.\n"
    "  - Binary Inverse: Piksel deÄŸeri eÅŸikten bÃ¼yÃ¼kse 0 (siyah), kÃ¼Ã§Ã¼kse 255 (beyaz) yapÄ±lÄ±r.\n\n"
    "ğŸ¯ Not: Bu iÅŸlem sadece gri tonlamalÄ± (grayscale) gÃ¶rÃ¼ntÃ¼ler iÃ§in geÃ§erlidir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Threshold Info\n\n"
    "â€¢ Threshold: A value between 0 and 255. It is used to convert pixels into binary form based on this threshold.\n\n"
    "â€¢ Threshold Type:\n"
    "  - Binary: If the pixel value is greater than the threshold, it becomes 255 (white); otherwise, it becomes 0 (black).\n"
    "  - Binary Inverse: If the pixel value is greater than the threshold, it becomes 0 (black); otherwise, it becomes 255 (white).\n\n"
    "ğŸ¯ Note: This operation only works on grayscale images."
)

    
    def __init__(self, frame):
        self.frame = frame
        self.create_widgets()
 
    def create_widgets(self):
        tk.Label(self.frame, text="Threshold:").grid(row=1, column=0, padx=2, pady=2)
        self.threshold_entry = tk.Entry(self.frame)
        self.threshold_entry.grid(row=1, column=1, padx=2, pady=2) 

        tk.Label(self.frame, text="Threshold Type:").grid(row=2, column=0, padx=2, pady=2)
        threshold_types = ["Binary", "Binary_Inverse"]
        self.threshold_type_combobox = ttk.Combobox(self.frame, values=threshold_types, width=17)
        self.threshold_type_combobox.grid(row=2, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= ThresholdingFrame.info_text)
     
    def apply(self, img):
        threshold_value = self.threshold_entry.get()
        threshold_type = self.threshold_type_combobox.get()
        
        if threshold_type == "Binary":
            threshold_type = cv2.THRESH_BINARY
            ret, img = cv2.threshold(img, int(threshold_value), 255, threshold_type)
        
        elif threshold_type == "Binary_Inverse":
            threshold_type = cv2.THRESH_BINARY_INV
            ret, img = cv2.threshold(img, int(threshold_value), 255, threshold_type)
    
        return img
          
class GaborFilterFrame(ProcessFrameBase):
    name = "Gabor Filter"
    info_text = (
    "ğŸ“Œ Gabor Filtresi Parametreleri\n\n"
    "â€¢ Ksize: Ã‡ekirdeÄŸin (kernel) boyutu. Tek sayÄ± ve pozitif olmalÄ±dÄ±r. Ã–rn: 3, 5, 7...\n"
    "â€¢ Sigma: Gauss daÄŸÄ±lÄ±mÄ±nÄ±n standart sapmasÄ±. Tipik aralÄ±k: 1.0 - 10.0\n"
    "â€¢ Theta: Filtrenin yÃ¶nÃ¼ (radyan cinsinden). 0 ile pi arasÄ±nda bir deÄŸerdir.\n"
    "â€¢ Lambda: SinÃ¼zoidal bileÅŸenin dalga boyu. Pozitif bir deÄŸerdir. Ã–rn: 4.0\n"
    "â€¢ Gamma: En-boy oranÄ±. Genellikle 0 ile 1 arasÄ±nda olur. 1: dairesel, <1: eliptik yapÄ±.\n"
    "â€¢ Phi: Faz kaymasÄ±. 0 ile 2*pi arasÄ±nda deÄŸer alabilir.\n\n"
    "ğŸ¯ Not: Gri seviyeli gÃ¶rsellerle daha iyi sonuÃ§ verir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Gabor Filter Parameters\n\n"
    "â€¢ Ksize: Kernel size. Must be a positive odd number. E.g., 3, 5, 7...\n"
    "â€¢ Sigma: Standard deviation of the Gaussian envelope. Typical range: 1.0 - 10.0\n"
    "â€¢ Theta: Orientation of the filter in radians. Should be between 0 and pi.\n"
    "â€¢ Lambda: Wavelength of the sinusoidal component. Must be positive. E.g., 4.0\n"
    "â€¢ Gamma: Aspect ratio. Usually between 0 and 1. 1: circular, <1: elliptical shape.\n"
    "â€¢ Phi: Phase offset. Should be between 0 and 2*pi.\n\n"
    "ğŸ¯ Note: Works best with grayscale images."
)

    
    def __init__(self, frame):
        self.frame = frame
        self.create_widgets()

    def create_widgets(self):
        tk.Label(self.frame, text="Ksize:").grid(row=1, column=0, padx=2, pady=2)
        self.ksize_entry = tk.Entry(self.frame)
        self.ksize_entry.grid(row=1, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Sigma:").grid(row=2, column=0, padx=2, pady=2)
        self.sigma_entry = tk.Entry(self.frame)
        self.sigma_entry.grid(row=2, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Theta:").grid(row=3, column=0, padx=2, pady=2)
        self.theta_entry = tk.Entry(self.frame)
        self.theta_entry.grid(row=3, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Lambda:").grid(row=4, column=0, padx=2, pady=2)
        self.lambda_frame = tk.Entry(self.frame)
        self.lambda_frame.grid(row=4, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Gamma:").grid(row=5, column=0, padx=2, pady=2)
        self.gamma_entry = tk.Entry(self.frame)
        self.gamma_entry.grid(row=5, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Phi:").grid(row=6, column=0, padx=2, pady=2)
        self.phi_entry = tk.Entry(self.frame)
        self.phi_entry.grid(row=6, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= GaborFilterFrame.info_text)

    def apply(self, img):
        
        ksize = int(self.ksize_entry.get())
        sigma = int(self.sigma_entry.get())
        theta = int(self.theta_entry.get())
        lamda = float(self.lambda_frame.get())
        gamma = float(self.gamma_entry.get())
        phi = int(self.phi_entry.get())
                
        ht_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)
        img = cv2.filter2D(img, cv2.CV_8UC3, ht_kernel)
        return img

class MorphologicalFrame(ProcessFrameBase):
    name = "Morphological" 
    info_text = (
    "ğŸ“Œ Morfolojik Ä°ÅŸlemler Parametreleri\n\n"
    "â€¢ Kernel Size: YapÄ±sal elemanÄ±n boyutudur. Pozitif ve tek sayÄ± olmalÄ±dÄ±r. Ã–rn: 3, 5, 7...\n"
    "â€¢ Kernel Shape: Ã‡ekirdek ÅŸeklidir. Rectangular (dikdÃ¶rtgen), Ellipse (elips), veya Cross (Ã§apraz) olabilir.\n"
    "â€¢ Operations: Uygulanacak morfolojik iÅŸlemi seÃ§in:\n"
    "  - Erode: Nesneleri kÃ¼Ã§Ã¼ltÃ¼r.\n"
    "  - Dilation: Nesneleri geniÅŸletir.\n"
    "  - Opening: GÃ¼rÃ¼ltÃ¼ temizleme (erode ardÄ±ndan dilation).\n"
    "  - Closing: KÃ¼Ã§Ã¼k boÅŸluklarÄ± kapatma (dilation ardÄ±ndan erode).\n"
    "  - Gradient: KenarlarÄ± Ã§Ä±karÄ±r (dilation - erode).\n"
    "  - Top Hat: Orijinal gÃ¶rÃ¼ntÃ¼ - Opening sonucu.\n"
    "  - Black Hat: Closing sonucu - Orijinal gÃ¶rÃ¼ntÃ¼.\n"
    "â€¢ Iterations: Ä°ÅŸlemin kaÃ§ kez uygulanacaÄŸÄ±nÄ± belirtir. Genellikle 1-5 arasÄ± kullanÄ±lÄ±r.\n\n"
    "ğŸ¯ Not: Gri seviyeli gÃ¶rÃ¼ntÃ¼lerle daha etkili sonuÃ§lar elde edilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Morphological Operations Parameters\n\n"
    "â€¢ Kernel Size: Size of the structuring element. Must be a positive odd number. E.g., 3, 5, 7...\n"
    "â€¢ Kernel Shape: Shape of the kernel. Can be Rectangular, Ellipse, or Cross.\n"
    "â€¢ Operations: Select the desired morphological operation:\n"
    "  - Erode: Shrinks objects.\n"
    "  - Dilation: Expands objects.\n"
    "  - Opening: Removes small noise (erode followed by dilation).\n"
    "  - Closing: Closes small holes (dilation followed by erode).\n"
    "  - Gradient: Extracts edges (dilation - erode).\n"
    "  - Top Hat: Original image - Opening result.\n"
    "  - Black Hat: Closing result - Original image.\n"
    "â€¢ Iterations: Number of times the operation is repeated. Usually between 1 and 5.\n\n"
    "ğŸ¯ Note: Grayscale images give better results for most morphological operations."
)

    
    def __init__(self, frame):
        self.frame = frame
        self.create_widgets()

    def create_widgets(self):
        tk.Label(self.frame, text="Kernel Size:").grid(row=1, column=0, padx=2, pady=2)
        self.kernelsize = tk.Entry(self.frame)
        self.kernelsize.grid(row=1, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Kernel Shape:").grid(row=2, column=0, padx=2, pady=2)
        shapes = ["Rectangular", "Ellipse", "Cross"]
        self.shapes_combobox = ttk.Combobox(self.frame, values=shapes, width=17)
        self.shapes_combobox.grid(row=2, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Operations:").grid(row=3, column=0, padx=2, pady=2)
        operations = ["Erode", "Dilation", "Opening", "Closing", "Gradient", "Top Hat", "Black Hat",]
        self.operations_combobox = ttk.Combobox(self.frame, values=operations, width=17)
        self.operations_combobox.grid(row=3, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Iterations:").grid(row=4, column=0, padx=2, pady=2)
        self.iterations = tk.Entry(self.frame)
        self.iterations.grid(row=4, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= MorphologicalFrame.info_text)

    def apply(self, img):
        kernel_shape = self.shapes_combobox.get()
        operations = self.operations_combobox.get()
        kernel_size = int(self.kernelsize.get())
        iterations_value = int(self.iterations.get())
        
        match kernel_shape:
            case "Rectangular":
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))
        
            case "Ellipse":
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size,kernel_size))
    
            case "Cross":
                kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size,kernel_size))
                
    
        match operations:
            case "Erode":
                img = cv2.morphologyEx(img, cv2.MORPH_ERODE, kernel, iterations = iterations_value) 
        
            case  "Dilation":
                img = cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel, iterations = iterations_value)

            case "Opening":
                img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations = iterations_value)
    
            case "Closing":
                img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations = iterations_value)
    
            case "Gradient":
                img = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel, iterations = iterations_value)
    
            case "Top Hat":
                img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel, iterations = iterations_value)
    
            case "Black Hat":
                img =  cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel, iterations = iterations_value)
                
        return img
#! May be Not working
class GammaTransformFrame(ProcessFrameBase):
    name = "Gamma Transform"
    info_text = (
    "ğŸ“Œ Gamma DÃ¶nÃ¼ÅŸÃ¼mÃ¼ Parametreleri\n\n"
    "â€¢ Gamma Value: GÃ¶rÃ¼ntÃ¼nÃ¼n parlaklÄ±ÄŸÄ±nÄ± ayarlayan pozitif bir deÄŸerdir. Genellikle 0.1 ile 5.0 arasÄ±nda olur.\n"
    "  - Gamma < 1: GÃ¶rÃ¼ntÃ¼ kararmaya baÅŸlar (daha koyu).\n"
    "  - Gamma > 1: GÃ¶rÃ¼ntÃ¼ aydÄ±nlanÄ±r (daha parlak).\n\n"
    "ğŸ¯ Not: GÃ¶rÃ¼ntÃ¼deki kontrastÄ± deÄŸiÅŸtirebilir, ancak aÅŸÄ±rÄ± deÄŸerler gÃ¶rsel bozulmalara yol aÃ§abilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Gamma Correction Parameters\n\n"
    "â€¢ Gamma Value: A positive value that adjusts the brightness of the image. It usually ranges between 0.1 and 5.0.\n"
    "  - Gamma < 1: The image becomes darker.\n"
    "  - Gamma > 1: The image becomes brighter.\n\n"
    "ğŸ¯ Note: It can change the contrast of the image, but extreme values may cause visual distortions."
)

    
    def __init__(self, frame):
        self.frame = frame
        self.create_widgets()
    
    def create_widgets(self):
        
        tk.Label(self.frame, text="Gamma Value:").grid(row=1, column=0, padx=2, pady=2)
        self.gamma_transform_entry = tk.Entry(self.frame)
        self.gamma_transform_entry.grid(row=1, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= GammaTransformFrame.info_text)


    def apply(self, img):
        gamma_transform_entry = int(self.gamma_transform_entry.get())

        # Normalize the image to the range [0, 1]
        normalized_image = img / 255.0
        
        # Apply gamma transform
        gamma_corrected = np.power(normalized_image, gamma_transform_entry)
        
        # Convert back to range [0, 255] and convert to uint8
        gamma_corrected = np.uint8(gamma_corrected * 255)
        
        return img
    
class CannyEdgeDetectorFrame(ProcessFrameBase):
    name = "Canny Edge Detection"
    info_text = (
    "ğŸ“Œ Canny Kenar AlgÄ±lama Parametreleri\n\n"
    "â€¢ Kernel Size: Canny algÄ±lama Ã§ekirdeÄŸinin boyutudur. Pozitif ve tek sayÄ± olmalÄ±dÄ±r. Ã–rn: 3, 5, 7...\n"
    "â€¢ Low Threshold: Canny algoritmasÄ±ndaki dÃ¼ÅŸÃ¼k eÅŸik deÄŸeridir. 0 ile 255 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Max Threshold: Canny algoritmasÄ±ndaki yÃ¼ksek eÅŸik deÄŸeridir. 0 ile 255 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ L2gradient: L2 normunun kullanÄ±lÄ±p kullanÄ±lmayacaÄŸÄ±nÄ± belirtir. True ya da False olarak seÃ§ilebilir.\n\n"
    "ğŸ¯ Not: DÃ¼ÅŸÃ¼k eÅŸik deÄŸeri, kenarlarÄ± daha hassas bir ÅŸekilde tespit eder. YÃ¼ksek eÅŸik deÄŸeri, sadece belirgin kenarlarÄ± alÄ±r.\n\n"
    "â€¢ GiriÅŸ GÃ¶rseli: Gri seviyeli bir gÃ¶rÃ¼ntÃ¼ olmalÄ±dÄ±r. Renkli gÃ¶rÃ¼ntÃ¼lerde de iÅŸlem yapÄ±labilir ancak en iyi sonuÃ§lar **gri seviyeli** gÃ¶rÃ¼ntÃ¼lerde alÄ±nÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Canny Edge Detection Parameters\n\n"
    "â€¢ Kernel Size: Size of the Canny detection kernel. Must be a positive odd number. E.g., 3, 5, 7...\n"
    "â€¢ Low Threshold: The low threshold value for Canny algorithm. It should be between 0 and 255.\n"
    "â€¢ Max Threshold: The high threshold value for Canny algorithm. It should be between 0 and 255.\n"
    "â€¢ L2gradient: Whether to use the L2 norm. Can be True or False.\n\n"
    "ğŸ¯ Note: A lower threshold captures finer edges, while a higher threshold detects more prominent edges.\n\n"
    "â€¢ Input Image: The image should be in grayscale. It can also work with color images, but the best results are achieved with **grayscale** images."
)

    
    def __init__(self, frame):
        self.frame = frame
        self.create_widgets()
        
    def create_widgets(self):
        
        tk.Label(self.frame, text="Kernel Size:").grid(row=1, column=0, padx=2, pady=2)
        self.ksize_entry = tk.Entry(self.frame)
        self.ksize_entry.grid(row=1, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Low Threshold:").grid(row=2, column=0, padx=2, pady=2)
        self.low_threshold_entry = tk.Entry(self.frame)
        self.low_threshold_entry.grid(row=2, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Max Threshold:").grid(row=3, column=0, padx=2, pady=2)
        self.max_threshold_entry = tk.Entry(self.frame)
        self.max_threshold_entry.grid(row=3, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="L2gradient:").grid(row=4, column=0, padx=2, pady=2)
        shape = ["True", "False"]
        self.l2gradient_combobox = ttk.Combobox(self.frame, values=shape, width=17)
        self.l2gradient_combobox .grid(row=4, column=1, padx=2, pady=2)
    
        self.info_buttom = ImageButtonApp(self.frame, text= CannyEdgeDetectorFrame.info_text)
    
    def apply(self, img):
        
        ksize = int(self.ksize_entry.get())
        low_threshold = int(self.low_threshold_entry.get())
        max_threshold = int(self.max_threshold_entry.get())
        l2gradient = bool(self.l2gradient_combobox.get())
        
        detected_edges = cv2.Canny(img, low_threshold, max_threshold, ksize, L2gradient= l2gradient)
    
        mask = detected_edges != 0
        img = img[:,:,None]
        dst = img * (mask[:,:,None].astype(img.dtype))
        
        img = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)
        
        return img

class HoughTransformFrame(ProcessFrameBase):
    name = "Hough Transform"   
    info_text = (
    "ğŸ“Œ Hough DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ile Ã‡evre AlgÄ±lama Parametreleri\n\n"
    "â€¢ Dp: Hough dÃ¶nÃ¼ÅŸÃ¼mÃ¼nde kullanÄ±lan Ã§Ã¶zÃ¼nÃ¼rlÃ¼k parametresidir. Genellikle 1.0 veya daha bÃ¼yÃ¼k bir deÄŸer olmalÄ±dÄ±r.\n"
    "â€¢ Minimum Distance: Tespit edilen daireler arasÄ±ndaki minimum mesafedir. Pozitif bir tamsayÄ± olmalÄ±dÄ±r.\n"
    "â€¢ Param1: Canny kenar algÄ±lama algoritmasÄ±ndaki yÃ¼ksek eÅŸik deÄŸeridir. 0 ile 255 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Param2: Dairelerin merkezinin bulunabilmesi iÃ§in gereken eÅŸik deÄŸeridir. 0 ile 100 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Minimum Radius: Tespit edilecek dairelerin minimum Ã§apÄ±dÄ±r. 0 ile 100 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Maximum Radius: Tespit edilecek dairelerin maksimum Ã§apÄ±dÄ±r. 0 ile 100 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Mark Color: Tespit edilen dairelerin iÅŸaretleneceÄŸi renk. SeÃ§enekler: KÄ±rmÄ±zÄ± (Red) veya Mavi (Blue).\n\n"
    "â€¢ GiriÅŸ GÃ¶rseli: GiriÅŸ gÃ¶rseli, gri seviyeli veya renkli olabilir, ancak genellikle gri seviyeli gÃ¶rsellerde daha net sonuÃ§lar alÄ±nÄ±r.\n"
    "ğŸ¯ Not: Dairelerin net bir ÅŸekilde tespit edilebilmesi iÃ§in giriÅŸ gÃ¶rselinin yÃ¼ksek kontrast ve net olmasÄ± Ã¶nerilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Hough Transform Circle Detection Parameters\n\n"
    "â€¢ Dp: The resolution parameter used in Hough transform. It should be a positive integer, usually 1.0 or higher.\n"
    "â€¢ Minimum Distance: The minimum distance between detected circles. It should be a positive integer.\n"
    "â€¢ Param1: The high threshold value for the Canny edge detection algorithm. It should be between 0 and 255.\n"
    "â€¢ Param2: The threshold for center detection of the circles. It should be between 0 and 100.\n"
    "â€¢ Minimum Radius: The minimum radius of circles to be detected. It should be between 0 and 100.\n"
    "â€¢ Maximum Radius: The maximum radius of circles to be detected. It should be between 0 and 100.\n"
    "â€¢ Mark Color: The color to mark detected circles. Options: Red or Blue.\n\n"
    "â€¢ Input Image: The input image can be grayscale or colored, but grayscale images generally produce sharper results.\n"
    "ğŸ¯ Note: For better results, the input image should have high contrast and sharp edges."
)
    
        
    def create_widgets(self):
        
        tk.Label(self.frame, text="Dp:").grid(row=1, column=0, padx=2, pady=2)
        self.dp_entry = tk.Entry(self.frame)
        self.dp_entry.grid(row=1, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Minimum Distance:").grid(row=2, column=0, padx=2, pady=2)
        self.minimum_distance_entry = tk.Entry(self.frame)
        self.minimum_distance_entry.grid(row=2, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Param1:").grid(row=3, column=0, padx=2, pady=2)
        self.param1_entry = tk.Entry(self.frame)
        self.param1_entry.grid(row=3, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Param2:").grid(row=4, column=0, padx=2, pady=2)
        self.param2_entry = tk.Entry(self.frame)
        self.param2_entry.grid(row=4, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Minimum Radius:").grid(row=5, column=0, padx=2, pady=2)
        self.minimum_radius_entry = tk.Entry(self.frame)
        self.minimum_radius_entry.grid(row=5, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Maximum Radius:").grid(row=6, column=0, padx=2, pady=2)
        self.maximum_radius_entry = tk.Entry(self.frame)
        self.maximum_radius_entry.grid(row=6, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Mark Color:").grid(row=7, column=0, padx=2, pady=2)
        ope2 = ["Red", "Blue"]
        self.mark_color_combobox = ttk.Combobox(self.frame, values=ope2, width=17)
        self.mark_color_combobox.grid(row=7, column=1, padx=2, pady=2)
    
        self.info_buttom = ImageButtonApp(self.frame, text= HoughTransformFrame.info_text)
    
    def apply(self, img):
        
        dp = int(self.dp_entry.get())
        minimum_distance = int(self.minimum_distance_entry.get())
        param1 = int(self.param1_entry.get())
        param2 = int(self.param2_entry.get())
        minimum_radius = int(self.minimum_radius_entry.get())
        maximum_radius = int(self.maximum_radius_entry.get())
        mark_color = str(self.mark_color_combobox.get())
        copy_img = img.copy()
        
        
        if mark_color == "Red":
            mark_color1 = 0
            mark_color2 = 0
            mark_color3 = 255
        
        elif mark_color == "Blue":
            mark_color1 = 255
            mark_color2 = 0
            mark_color3 = 0
        
        circles = cv2.HoughCircles(
        img, 
        cv2.HOUGH_GRADIENT, dp = dp, minDist = minimum_distance, param1 = param1, param2 = param2, minRadius = minimum_radius, maxRadius = maximum_radius 
    )
    
        if circles is not None:
            circles = np.uint16(np.around(circles))
            for circle in circles[0, :]:
                center = (circle[0], circle[1])
                radius = circle[2]
                cv2.circle(copy_img, center, radius, (mark_color1, mark_color2, mark_color3), 2)
        
        return copy_img
        
class GaussianBlurFrame(ProcessFrameBase):
    name = "Gaussian Blur"    
    info_text = (
    "ğŸ“Œ Hough DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ile Ã‡evre AlgÄ±lama Parametreleri\n\n"
    "â€¢ Dp: Hough dÃ¶nÃ¼ÅŸÃ¼mÃ¼nde kullanÄ±lan Ã§Ã¶zÃ¼nÃ¼rlÃ¼k parametresidir. Genellikle 1.0 veya daha bÃ¼yÃ¼k bir deÄŸer olmalÄ±dÄ±r.\n"
    "â€¢ Minimum Distance: Tespit edilen daireler arasÄ±ndaki minimum mesafedir. Pozitif bir tamsayÄ± olmalÄ±dÄ±r.\n"
    "â€¢ Param1: Canny kenar algÄ±lama algoritmasÄ±ndaki yÃ¼ksek eÅŸik deÄŸeridir. 0 ile 255 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Param2: Dairelerin merkezinin bulunabilmesi iÃ§in gereken eÅŸik deÄŸeridir. 0 ile 100 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Minimum Radius: Tespit edilecek dairelerin minimum Ã§apÄ±dÄ±r. 0 ile 100 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Maximum Radius: Tespit edilecek dairelerin maksimum Ã§apÄ±dÄ±r. 0 ile 100 arasÄ±nda olmalÄ±dÄ±r.\n"
    "â€¢ Mark Color: Tespit edilen dairelerin iÅŸaretleneceÄŸi renk. SeÃ§enekler: KÄ±rmÄ±zÄ± (Red) veya Mavi (Blue).\n\n"
    "ğŸ¯ Not: Dairelerin net bir ÅŸekilde tespit edilebilmesi iÃ§in giriÅŸ gÃ¶rselinin yÃ¼ksek kontrast ve net olmasÄ± Ã¶nerilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Hough Transform Circle Detection Parameters\n\n"
    "â€¢ Dp: The resolution parameter used in Hough transform. It should be a positive integer, usually 1.0 or higher.\n"
    "â€¢ Minimum Distance: The minimum distance between detected circles. It should be a positive integer.\n"
    "â€¢ Param1: The high threshold value for the Canny edge detection algorithm. It should be between 0 and 255.\n"
    "â€¢ Param2: The threshold for center detection of the circles. It should be between 0 and 100.\n"
    "â€¢ Minimum Radius: The minimum radius of circles to be detected. It should be between 0 and 100.\n"
    "â€¢ Maximum Radius: The maximum radius of circles to be detected. It should be between 0 and 100.\n"
    "â€¢ Mark Color: The color to mark detected circles. Options: Red or Blue.\n\n"
    "ğŸ¯ Note: For better results, the input image should have high contrast and sharp edges."
)

    
    def create_widgets(self):
        
        tk.Label(self.frame, text="Kernel Size:").grid(row=1, column=0, padx=2, pady=2)
        self.ksize_entry = tk.Entry(self.frame)
        self.ksize_entry.grid(row=1, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Sigma_X:").grid(row=2, column=0, padx=2, pady=2)
        self.sigmax_entry = tk.Entry(self.frame)
        self.sigmax_entry.grid(row=2, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Sigma_Y:").grid(row=3, column=0, padx=2, pady=2)
        self.sigmay_entry = tk.Entry(self.frame)
        self.sigmay_entry.grid(row=3, column=1, padx=2, pady=2)
    
        self.info_buttom = ImageButtonApp(self.frame, text= GaussianBlurFrame.info_text)
    
    def apply(self, img):
        
        ksize = int(self.ksize_entry.get())
        sigmax = float(self.sigmax_entry.get())
        sigmay = float(self.sigmay_entry.get())
        
        img = cv2.GaussianBlur(img, (ksize, ksize), sigmax, sigmay)
    
        return img

class KitterIllingworthFrame(ProcessFrameBase):
    name = "Kittler-Illingworth"
    info_text = (
    "ğŸ“Œ Kittler-Illingworth Optimum EÅŸik DeÄŸeri Parametreleri\n\n"
    "â€¢ Optimum Threshold: Kittler-Illingworth yÃ¶ntemine dayalÄ± olarak gÃ¶rÃ¼ntÃ¼deki optimum eÅŸik deÄŸeri.\n"
    "â€¢ Kittler-Illingworth yÃ¶ntemi, gÃ¶rÃ¼ntÃ¼ histogramÄ±ndaki iki sÄ±nÄ±fÄ± (arka plan ve Ã¶n plan) ayÄ±ran eÅŸik deÄŸerini bulur.\n"
    "â€¢ Bu yÃ¶ntem, sÄ±nÄ±flarÄ±n varyanslarÄ±nÄ± dikkate alarak en dÃ¼ÅŸÃ¼k maliyeti veren eÅŸik deÄŸerini belirler.\n\n"
    "ğŸ¯ Not: Kittler-Illingworth yÃ¶ntemi, Ã¶zellikle aydÄ±nlÄ±k ve karanlÄ±k bÃ¶lgelerin net bir ÅŸekilde ayrÄ±ldÄ±ÄŸÄ± gÃ¶rÃ¼ntÃ¼lerde daha iyi sonuÃ§ verir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Kittler-Illingworth Optimum Threshold Parameters\n\n"
    "â€¢ Optimum Threshold: The optimum threshold based on the Kittler-Illingworth method for separating background and foreground.\n"
    "â€¢ The Kittler-Illingworth method determines the threshold value that minimizes the cost function, considering the variance of both classes (background and foreground).\n\n"
    "ğŸ¯ Note: The Kittler-Illingworth method works best for images where the background and foreground are clearly separated."
)

    
    def create_widgets(self):
        
        tk.Label(self.frame, text="Optimum Threshold:").grid(row=1, column=0, padx=2, pady=2)
        self.optimum_threshold_label = tk.Label(self.frame)
        self.optimum_threshold_label.grid(row=1, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= KitterIllingworthFrame.info_text)
        
    def apply(self, img):
        
        # GÃ¶rÃ¼ntÃ¼nÃ¼n histogramÄ±nÄ± hesapla
        hist = cv2.calcHist([img], [0], None, [256], [0,256])
        hist_norm = hist.ravel()/hist.sum()
        thresholds = np.array(range(256))

        # EÅŸik deÄŸerleri iÃ§in Kittler-Illingworth hesaplama
        def calculate_cost(t):
            background = hist_norm[:t]
            foreground = hist_norm[t:]
            background_mean = np.sum(thresholds[:t]*background)
            foreground_mean = np.sum(thresholds[t:]*foreground)
            background_variance = np.sum(((thresholds[:t] - background_mean) ** 2) * background)
            foreground_variance = np.sum(((thresholds[t:] - foreground_mean) ** 2) * foreground)
            cost = background_variance * np.log(background_variance if background_variance > 0 else 1) + \
                foreground_variance * np.log(foreground_variance if foreground_variance > 0 else 1)
            return cost

        costs = [calculate_cost(t) for t in range(1, 256)]
        optimal_threshold = np.argmin(costs) + 1
        print(optimal_threshold)
        return optimal_threshold
    
    def update_result(self, img):
        threshold = self.apply(img)
        self.optimum_threshold_label.config(text=str(threshold))

class DrawHistogramFrame(ProcessFrameBase):
    name = "Draw Histogram"
    info_text = (
    "ğŸ“Œ GÃ¶rÃ¼ntÃ¼ HistogramÄ± Ã‡izimi Parametreleri\n\n"
    "â€¢ GÃ¶rÃ¼ntÃ¼ HistogramÄ±: GÃ¶rÃ¼ntÃ¼deki piksellerin renk yoÄŸunluklarÄ±nÄ± gÃ¶steren bir grafiktir.\n"
    "â€¢ Histogram, gÃ¶rÃ¼ntÃ¼deki farklÄ± renk yoÄŸunluklarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±nÄ± analiz etmek iÃ§in kullanÄ±lÄ±r.\n"
    "â€¢ Bu iÅŸlem, her pikselin gri ton deÄŸeri iÃ§in frekanslarÄ± hesaplar ve bir histogram oluÅŸturur.\n\n"
    "ğŸ¯ Not: Histogram analizi, kontrast, parlaklÄ±k ayarlarÄ± veya gÃ¶rÃ¼ntÃ¼ iyileÅŸtirme tekniklerini belirlemek iÃ§in faydalÄ±dÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Image Histogram Drawing Parameters\n\n"
    "â€¢ Image Histogram: A graph that shows the frequency of pixel intensities in an image.\n"
    "â€¢ The histogram represents the distribution of pixel values across the image, useful for image analysis.\n"
    "â€¢ This operation calculates the frequency of each grayscale value and creates a histogram.\n\n"
    "ğŸ¯ Note: Histogram analysis is useful for determining contrast, brightness settings, or image enhancement techniques."
)

    
    def create_widgets(self):
        self.info_buttom = ImageButtonApp(self.frame, text= DrawHistogramFrame.info_text)
    
    def apply(self, img):
        
        histogram, bins = np.histogram(img.flatten(), bins=256, range=[0,256])
    
        return histogram, bins
    
    def update_result(self, img):
        
        histogram, bins = self.apply(img)
        
        plt.figure(figsize=(10,6))
        plt.plot(bins[:-1], histogram, color='black')
        plt.title('Image Histogram')
        plt.xlabel('Pixel Intensity')
        plt.ylabel('Frequency')    

class ColorConvertFrame(ProcessFrameBase):
    name = "Color Conversion"
    info_text = (
    "ğŸ“Œ Renk DÃ¶nÃ¼ÅŸÃ¼mÃ¼ Parametreleri\n\n"
    "â€¢ RGB'den Grayscale'e: Renkli bir gÃ¶rÃ¼ntÃ¼yÃ¼ gri tonlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Her pikselin gri ton deÄŸeri hesaplanÄ±r.\n"
    "â€¢ Grayscale'den RGB'ye: Gri tonlu bir gÃ¶rÃ¼ntÃ¼yÃ¼ renklendirilmiÅŸ (RGB) gÃ¶rÃ¼ntÃ¼ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Ancak orijinal renk bilgisi kaybolur.\n"
    "â€¢ RGB'den HSV'ye: Renkli bir gÃ¶rÃ¼ntÃ¼yÃ¼, renk (Hue), doygunluk (Saturation) ve parlaklÄ±k (Value) bileÅŸenlerine ayÄ±rÄ±r.\n"
    "â€¢ HSV'den RGB'ye: HSV formatÄ±ndaki bir gÃ¶rÃ¼ntÃ¼yÃ¼, kÄ±rmÄ±zÄ±-yeÅŸil-mavi (RGB) formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n\n"
    "ğŸ¯ Not: GÃ¶rÃ¼ntÃ¼ iÅŸleme ve renk analizi iÃ§in uygun renk dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ seÃ§mek Ã¶nemlidir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Color Conversion Parameters\n\n"
    "â€¢ RGB to Grayscale: Converts a color image to grayscale. Each pixel is converted to a corresponding grayscale value.\n"
    "â€¢ Grayscale to RGB: Converts a grayscale image back to RGB. The original color information is lost.\n"
    "â€¢ RGB to HSV: Converts an image from RGB to HSV, separating hue, saturation, and value components.\n"
    "â€¢ HSV to RGB: Converts an image from HSV back to RGB.\n\n"
    "ğŸ¯ Note: Selecting the appropriate color conversion is crucial for image processing and color analysis."
)


    def create_widgets(self):
        tk.Label(self.frame, text="Select Color Conversion:").grid(row=1, column=0, padx=2, pady=2)
        
        # Combobox for color conversion type
        self.color_convert_combobox = ttk.Combobox(self.frame, values=["RGB to Grayscale", "Grayscale to RGB", "RGB to HSV", "HSV to RGB"])
        self.color_convert_combobox.grid(row=1, column=1, padx=2, pady=2)
        self.color_convert_combobox.set("RGB to Grayscale")

        self.info_buttom = ImageButtonApp(self.frame, text= ColorConvertFrame.info_text)

    def apply(self, img):
        conversion_type = self.color_convert_combobox.get()

        match conversion_type:
            case "RGB to Grayscale":
                # Convert image from RGB to Grayscale
                converted_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            case "Grayscale to RGB":
                # Convert image from Grayscale to RGB
                converted_image = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            case "RGB to HSV":
                # Convert image from RGB to HSV
                converted_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
            case "HSV to RGB":
                # Convert image from HSV to RGB
                converted_image = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)
            case _:
                # Default case if no match
                converted_image = img

        return converted_image

class ResizeFrame(ProcessFrameBase):
    name = "Resize"
    info_text = (
    "ğŸ“Œ GÃ¶rÃ¼ntÃ¼ Yeniden BoyutlandÄ±rma Parametreleri\n\n"
    "â€¢ Width (GeniÅŸlik): GÃ¶rÃ¼ntÃ¼nÃ¼n yeni geniÅŸliÄŸi. Pozitif bir tamsayÄ± deÄŸeri olmalÄ±dÄ±r.\n"
    "â€¢ Height (YÃ¼kseklik): GÃ¶rÃ¼ntÃ¼nÃ¼n yeni yÃ¼ksekliÄŸi. Pozitif bir tamsayÄ± deÄŸeri olmalÄ±dÄ±r.\n\n"
    "ğŸ¯ Not: GÃ¶rÃ¼ntÃ¼ boyutlarÄ± deÄŸiÅŸtirilirken orijinal gÃ¶rÃ¼ntÃ¼nÃ¼n en-boy oranÄ± korunmaz, bu da distorsiyona neden olabilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Image Resizing Parameters\n\n"
    "â€¢ Width: The new width of the image. It should be a positive integer.\n"
    "â€¢ Height: The new height of the image. It should be a positive integer.\n\n"
    "ğŸ¯ Note: Resizing the image may cause distortion as the original aspect ratio is not preserved."
)


    def create_widgets(self):
        tk.Label(self.frame, text="Width:").grid(row=1, column=0, padx=2, pady=2)
        self.width_entry = tk.Entry(self.frame)
        self.width_entry.grid(row=1, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Height:").grid(row=2, column=0, padx=2, pady=2)
        self.height_entry = tk.Entry(self.frame)
        self.height_entry.grid(row=2, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= ResizeFrame.info_text)

    def apply(self, img):
        width = int(self.width_entry.get())
        height = int(self.height_entry.get())

        # Resize the image
        resized_image = cv2.resize(img, (width, height))

        return resized_image

class RotateFrame(ProcessFrameBase):
    name = "Rotate"
    info_text = (
    "ğŸ“Œ GÃ¶rÃ¼ntÃ¼ DÃ¶ndÃ¼rme Parametreleri\n\n"
    "â€¢ Rotation Angle (DÃ¶nme AÃ§Ä±sÄ±): GÃ¶rÃ¼ntÃ¼nÃ¼n dÃ¶neceÄŸi aÃ§Ä±. SeÃ§enekler: 90Â°, 180Â°, 270Â°.\n\n"
    "ğŸ¯ Not: SeÃ§ilen dÃ¶ndÃ¼rme aÃ§Ä±sÄ±, gÃ¶rÃ¼ntÃ¼yÃ¼ saat yÃ¶nÃ¼nde veya saat yÃ¶nÃ¼nÃ¼n tersine dÃ¶ndÃ¼rÃ¼r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Image Rotation Parameters\n\n"
    "â€¢ Rotation Angle: The angle by which the image will be rotated. Options: 90Â°, 180Â°, 270Â°.\n\n"
    "ğŸ¯ Note: The selected rotation angle will rotate the image clockwise or counterclockwise."
)


    def create_widgets(self):
        tk.Label(self.frame, text="Select Rotation Angle:").grid(row=1, column=0, padx=2, pady=2)
        
        # Combobox for rotation angles
        self.rotation_combobox = ttk.Combobox(self.frame, values=["90", "180", "270"])
        self.rotation_combobox.grid(row=1, column=1, padx=2, pady=2)
        self.rotation_combobox.set("90")

        self.info_buttom = ImageButtonApp(self.frame, text= RotateFrame.info_text)

    def apply(self, img):
        rotation_angle = int(self.rotation_combobox.get())

        match rotation_angle:
            case 90:
                rotated_image = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
            case 180:
                rotated_image = cv2.rotate(img, cv2.ROTATE_180)
            case 270:
                rotated_image = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
            case _:
                rotated_image = img

        return rotated_image

class FlipFrame(ProcessFrameBase):
    name = "Flip"
    info_text = (
    "ğŸ“Œ GÃ¶rÃ¼ntÃ¼ Ã‡evirme Parametreleri\n\n"
    "â€¢ Flip Direction (Ã‡evirme YÃ¶nÃ¼): GÃ¶rÃ¼ntÃ¼nÃ¼n hangi yÃ¶nde Ã§evrileceÄŸi. SeÃ§enekler: Yatay (Horizontal), Dikey (Vertical), Her Ä°ki YÃ¶n (Both).\n\n"
    "ğŸ¯ Not: Yatay Ã§evirme, gÃ¶rÃ¼ntÃ¼yÃ¼ soldan saÄŸa ters Ã§evirir; dikey Ã§evirme, gÃ¶rÃ¼ntÃ¼yÃ¼ yukarÄ±dan aÅŸaÄŸÄ±ya ters Ã§evirir. Her iki yÃ¶n seÃ§ildiÄŸinde, hem yatay hem de dikey olarak tersine dÃ¶ner.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Image Flip Parameters\n\n"
    "â€¢ Flip Direction: The direction in which the image will be flipped. Options: Horizontal, Vertical, Both.\n\n"
    "ğŸ¯ Note: Horizontal flip reverses the image left to right; vertical flip reverses the image top to bottom. Choosing both flips will reverse the image in both directions."
)


    def create_widgets(self):
        tk.Label(self.frame, text="Select Flip Direction:").grid(row=1, column=0, padx=2, pady=2)
        
        # Combobox for flip directions
        self.flip_combobox = ttk.Combobox(self.frame, values=["Horizontal", "Vertical", "Both"])
        self.flip_combobox.grid(row=1, column=1, padx=2, pady=2)
        self.flip_combobox.set("Horizontal")
        
        self.info_buttom = ImageButtonApp(self.frame, text= FlipFrame.info_text)

    def apply(self, img):
        flip_direction = self.flip_combobox.get()

        match flip_direction:
            case "Horizontal":
                flipped_image = cv2.flip(img, 1)  # Flip horizontally
            case "Vertical":
                flipped_image = cv2.flip(img, 0)  # Flip vertically
            case "Both":
                flipped_image = cv2.flip(img, -1)  # Flip both horizontally and vertically
            case _:
                flipped_image = img

        return flipped_image
    
class MedianBlurFrame(ProcessFrameBase):
    name = "Median Blur"
    info_text = (
    "ğŸ“Œ Median Blur (Medyan BulanÄ±klÄ±ÄŸÄ±) Parametreleri\n\n"
    "â€¢ Kernel Size (Ã‡ekirdek Boyutu): Median bulanÄ±klÄ±k algoritmasÄ±nda kullanÄ±lan Ã§ekirdek boyutudur. Genellikle tek sayÄ±lar (3, 5, 7 vb.) kullanÄ±lÄ±r.\n\n"
    "ğŸ¯ Not: Ã‡ekirdek boyutunu arttÄ±rmak, daha fazla bulanÄ±klÄ±k saÄŸlar, ancak detaylarÄ±n kaybolmasÄ±na da yol aÃ§abilir. GÃ¶rÃ¼ntÃ¼deki gÃ¼rÃ¼ltÃ¼leri yumuÅŸatmak iÃ§in uygundur.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Median Blur Parameters\n\n"
    "â€¢ Kernel Size: The size of the kernel used in the median blur algorithm. Typically, odd numbers (3, 5, 7, etc.) are used.\n\n"
    "ğŸ¯ Note: Increasing the kernel size results in more blur, but it may also cause the loss of finer details. It's useful for smoothing out noise in an image."
)


    def create_widgets(self):
        tk.Label(self.frame, text="Kernel Size:").grid(row=1, column=0, padx=2, pady=2)
        self.kernel_size_entry = tk.Entry(self.frame)
        self.kernel_size_entry.grid(row=1, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= MedianBlurFrame.info_text)

    def apply(self, img):
        kernel_size = int(self.kernel_size_entry.get())

        # Apply Median Blur
        blurred_image = cv2.medianBlur(img, kernel_size)

        return blurred_image

#! May be not working
class BilateralFilterFrame(ProcessFrameBase):
    name = "Bilateral Filter"
    info_text = (
    "ğŸ“Œ Bilateral Filter (Ä°ki TaraflÄ± Filtre) Parametreleri\n\n"
    "â€¢ Diameter: Filtreleme sÄ±rasÄ±nda her pikselin Ã§evresinde kullanÄ±lacak piksel komÅŸuluÄŸunun Ã§apÄ±. Pozitif bir tamsayÄ± olmalÄ±dÄ±r.\n"
    "â€¢ Sigma Color: Renk uzayÄ±ndaki standart sapmadÄ±r. Bu deÄŸer arttÄ±kÃ§a, benzer renklerdeki pikseller daha fazla etkilenir.\n"
    "â€¢ Sigma Space: Uzamsal koordinatlar arasÄ±ndaki mesafeye gÃ¶re olan standart sapmadÄ±r. Bu deÄŸer arttÄ±kÃ§a, daha uzak pikseller filtreye dahil edilir.\n\n"
    "ğŸ¯ Not: Bilateral filtre, kenarlarÄ± koruyarak gÃ¼rÃ¼ltÃ¼yÃ¼ azaltmak iÃ§in idealdir. Bu nedenle kenar netliÄŸinin korunmasÄ± istenen gÃ¶rÃ¼ntÃ¼lerde tercih edilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Bilateral Filter Parameters\n\n"
    "â€¢ Diameter: Diameter of each pixel neighborhood used during filtering. Should be a positive integer.\n"
    "â€¢ Sigma Color: Standard deviation in the color space. Higher values mean that farther colors within the neighborhood will be mixed together.\n"
    "â€¢ Sigma Space: Standard deviation in the coordinate space. Higher values mean that farther pixels will influence each other.\n\n"
    "ğŸ¯ Note: Bilateral filter is ideal for reducing noise while preserving edges. Itâ€™s commonly used when edge sharpness must be maintained."
)


    def create_widgets(self):
        tk.Label(self.frame, text="Diameter:").grid(row=1, column=0, padx=2, pady=2)
        self.d_entry = tk.Entry(self.frame)
        self.d_entry.grid(row=1, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Sigma Color:").grid(row=2, column=0, padx=2, pady=2)
        self.sigma_color_entry = tk.Entry(self.frame)
        self.sigma_color_entry.grid(row=2, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Sigma Space:").grid(row=3, column=0, padx=2, pady=2)
        self.sigma_space_entry = tk.Entry(self.frame)
        self.sigma_space_entry.grid(row=3, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= BilateralFilterFrame.info_text)

    def apply(self, img):
        d = int(self.d_entry.get())
        sigma_color = float(self.sigma_color_entry.get())
        sigma_space = float(self.sigma_space_entry.get())

        # Apply Bilateral Filter
        filtered_image = cv2.bilateralFilter(img, d, sigma_color, sigma_space)

        return filtered_image

class Filter2DFrame(ProcessFrameBase):
    name = "Filter2D"
    info_text = (
    "ğŸ“Œ filter2D KonvolÃ¼syon Ä°ÅŸlemi Parametreleri\n\n"
    "â€¢ 3x3 Kernel: GÃ¶rÃ¼ntÃ¼ Ã¼zerine uygulanacak Ã§ekirdek (kernel) deÄŸerlerini ifade eder.\n"
    "  Bu deÄŸerler, konvolÃ¼syon iÅŸleminde her pikselin komÅŸularÄ±yla nasÄ±l birleÅŸtirileceÄŸini belirler.\n"
    "  Ã–rneÄŸin, kenar algÄ±lama, bulanÄ±klaÅŸtÄ±rma veya keskinleÅŸtirme iÅŸlemleri iÃ§in farklÄ± Ã§ekirdekler kullanÄ±labilir.\n\n"
    "ğŸ¯ Not: Girdi gÃ¶rÃ¼ntÃ¼sÃ¼ net ve kontrastlÄ± olursa konvolÃ¼syon etkisi daha belirgin olur.\n"
    "      Kernel deÄŸerlerinin toplamÄ± yÃ¼ksekse gÃ¶rÃ¼ntÃ¼ aydÄ±nlanabilir; negatif deÄŸerler keskinleÅŸtirme saÄŸlar.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ filter2D Convolution Parameters\n\n"
    "â€¢ 3x3 Kernel: Represents the kernel values to be applied over the image.\n"
    "  These values define how each pixel is combined with its neighbors during the convolution operation.\n"
    "  Different kernels are used for edge detection, blurring, or sharpening.\n\n"
    "ğŸ¯ Note: A sharp and high-contrast input image will yield more visible convolution effects.\n"
    "      If the kernel values sum up to a high value, the output image may become brighter; negative values enhance edges."
)


    def create_widgets(self):
        tk.Label(self.frame, text="3x3 Kernel Values (row-wise):").grid(row=1, column=0, columnspan=2, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= Filter2DFrame.info_text)

        inner_frame = tk.Frame(self.frame)
        inner_frame.grid(row=2, column=0)
        
        # 3x3 Entry grid for kernel values
        self.kernel_entries = []
        for i in range(3):
            row_entries = []
            for j in range(3):
                entry = tk.Entry(inner_frame, width=5)
                entry.grid(row=i+2, column=j, padx=1, pady=1)
                entry.insert(0, "0")
                row_entries.append(entry)
            self.kernel_entries.append(row_entries)

    def apply(self, img):
        # Read kernel values from Entry widgets and convert to float
        kernel = []
        for row in self.kernel_entries:
            row_values = [float(entry.get()) for entry in row]
            kernel.append(row_values)
        kernel = np.array(kernel, dtype=np.float32)

        # Apply filter2D
        filtered_image = cv2.filter2D(img, -1, kernel)

        return filtered_image

class SobelFrame(ProcessFrameBase):
    name = "Sobel Edge Detection"
    info_text = (
    "ğŸ“Œ Sobel Kenar AlgÄ±lama Parametreleri\n\n"
    "â€¢ dx: x ekseni yÃ¶nÃ¼nde tÃ¼rev alÄ±nÄ±p alÄ±nmayacaÄŸÄ±nÄ± belirtir. 1 ise x yÃ¶nlÃ¼ kenarlarÄ± algÄ±lar.\n"
    "â€¢ dy: y ekseni yÃ¶nÃ¼nde tÃ¼rev alÄ±nÄ±p alÄ±nmayacaÄŸÄ±nÄ± belirtir. 1 ise y yÃ¶nlÃ¼ kenarlarÄ± algÄ±lar.\n"
    "â€¢ Kernel Size: Sobel filtresinde kullanÄ±lacak Ã§ekirdek boyutudur. Pozitif tek sayÄ± (Ã¶rneÄŸin: 1, 3, 5) olmalÄ±dÄ±r.\n\n"
    "ğŸ¯ Not: dx ve dy birlikte 1 olarak seÃ§ilirse hem yatay hem dikey kenarlar algÄ±lanÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Sobel Edge Detection Parameters\n\n"
    "â€¢ dx: Specifies whether to take the derivative in the x-direction. 1 detects horizontal edges.\n"
    "â€¢ dy: Specifies whether to take the derivative in the y-direction. 1 detects vertical edges.\n"
    "â€¢ Kernel Size: The size of the kernel to be used in the Sobel filter. It must be an odd positive integer (e.g., 1, 3, 5).\n\n"
    "ğŸ¯ Note: If both dx and dy are set to 1, both horizontal and vertical edges are detected."
)


    def create_widgets(self):
        # dx selecting
        tk.Label(self.frame, text="dx:").grid(row=1, column=0, padx=2, pady=2)
        self.dx_combobox = ttk.Combobox(self.frame, values=[0, 1])
        self.dx_combobox.grid(row=1, column=1, padx=2, pady=2)

        # dy selecting
        tk.Label(self.frame, text="dy:").grid(row=2, column=0, padx=2, pady=2)
        self.dy_combobox = ttk.Combobox(self.frame, values=[0, 1])
        self.dy_combobox.grid(row=2, column=1, padx=2, pady=2)

        # Ksize
        tk.Label(self.frame, text="Kernel Size (odd, e.g. 1, 3, 5):").grid(row=3, column=0, padx=2, pady=2)
        self.ksize_entry = tk.Entry(self.frame)
        self.ksize_entry.grid(row=3, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= SobelFrame.info_text)

    def apply(self, img):
        dx = int(self.dx_combobox.get())
        dy = int(self.dy_combobox.get())
        ksize = int(self.ksize_entry.get())

        # Apply
        sobel_image = cv2.Sobel(img, cv2.CV_64F, dx, dy, ksize=ksize)

        # Normalize image and convert to uint8
        sobel_image = cv2.convertScaleAbs(sobel_image)

        return sobel_image

class ScharrFrame(ProcessFrameBase):
    name = "Scharr Edge Detection"
    info_text = (
    "ğŸ“Œ Scharr Kenar AlgÄ±lama Parametreleri\n\n"
    "â€¢ dx: x ekseni yÃ¶nÃ¼nde tÃ¼rev alÄ±nÄ±p alÄ±nmayacaÄŸÄ±nÄ± belirtir. 1 seÃ§ilirse yatay kenarlarÄ± algÄ±lar.\n"
    "â€¢ dy: y ekseni yÃ¶nÃ¼nde tÃ¼rev alÄ±nÄ±p alÄ±nmayacaÄŸÄ±nÄ± belirtir. 1 seÃ§ilirse dikey kenarlarÄ± algÄ±lar.\n\n"
    "ğŸ¯ Not: Scharr filtresi, Ã¶zellikle kÃ¼Ã§Ã¼k Ã§ekirdek boyutlarÄ±nda (Ã¶rneÄŸin 3x3) Sobel filtresine gÃ¶re daha hassas sonuÃ§lar verir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Scharr Edge Detection Parameters\n\n"
    "â€¢ dx: Indicates whether to compute the derivative in the x-direction. 1 detects horizontal edges.\n"
    "â€¢ dy: Indicates whether to compute the derivative in the y-direction. 1 detects vertical edges.\n\n"
    "ğŸ¯ Note: The Scharr filter provides more accurate results than the Sobel filter, especially for small kernel sizes like 3x3."
)


    def create_widgets(self):
        # dx selecting
        tk.Label(self.frame, text="dx:").grid(row=1, column=0, padx=2, pady=2)
        self.dx_combobox = ttk.Combobox(self.frame, values=[0, 1])
        self.dx_combobox.grid(row=1, column=1, padx=2, pady=2)

        # dy selecting
        tk.Label(self.frame, text="dy:").grid(row=2, column=0, padx=2, pady=2)
        self.dy_combobox = ttk.Combobox(self.frame, values=[0, 1])
        self.dy_combobox.grid(row=2, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= ScharrFrame.info_text)

    def apply(self, img):
        dx = int(self.dx_combobox.get())
        dy = int(self.dy_combobox.get())

        # Apply
        scharr_image = cv2.Scharr(img, cv2.CV_64F, dx, dy)

        # Normalize image and convert to uint8
        scharr_image = cv2.convertScaleAbs(scharr_image)

        return scharr_image

class LaplacianFrame(ProcessFrameBase):
    name = "Laplacian Edge Detection"
    info_text = (
    "ğŸ“Œ Laplace Kenar AlgÄ±lama Parametresi\n\n"
    "â€¢ Kernel Size: TÃ¼revi alÄ±rken kullanÄ±lan Ã§ekirdek (kernel) boyutu. Tek sayÄ± ve pozitif olmalÄ±dÄ±r (Ã¶rn. 1, 3, 5).\n"
    "Daha bÃ¼yÃ¼k deÄŸerler daha fazla kenar detayÄ± Ã§Ä±karabilir fakat aynÄ± zamanda gÃ¶rÃ¼ntÃ¼de bulanÄ±klÄ±ÄŸa da yol aÃ§abilir.\n\n"
    "ğŸ¯ Not: Laplace operatÃ¶rÃ¼, gÃ¶rÃ¼ntÃ¼deki ikinci tÃ¼rev bilgisini kullanarak kenarlarÄ± simetrik olarak algÄ±lar.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Laplacian Edge Detection Parameter\n\n"
    "â€¢ Kernel Size: The size of the filter kernel used for computing the derivative. Must be a positive odd number (e.g., 1, 3, 5).\n"
    "Larger values may enhance edge details but also introduce blurring.\n\n"
    "ğŸ¯ Note: The Laplacian operator uses the second derivative of the image to detect edges symmetrically."
)


    def create_widgets(self):
        # Entry for kernel size (must be odd and positive)
        tk.Label(self.frame, text="Kernel Size (e.g., 1, 3, 5):").grid(row=1, column=0, padx=2, pady=2)
        self.ksize_entry = tk.Entry(self.frame)
        self.ksize_entry.grid(row=1, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= LaplacianFrame.info_text)

    def apply(self, img):
        ksize = int(self.ksize_entry.get())

        # Apply Laplacian operator using 64-bit float depth
        laplacian_image = cv2.Laplacian(img, cv2.CV_64F, ksize=ksize)

        # Convert the result to 8-bit absolute values for display
        laplacian_image = cv2.convertScaleAbs(laplacian_image)

        return laplacian_image

class CornerHarrisFrame(ProcessFrameBase):
    name = "Harris Corner Detection"
    info_text = (
    "ğŸ“Œ Harris KÃ¶ÅŸe AlgÄ±lama Parametreleri\n\n"
    "â€¢ Block Size: Her piksel iÃ§in kÃ¶ÅŸe algÄ±lamada kullanÄ±lan komÅŸuluk boyutu.\n"
    "â€¢ Sobel Kernel Size: TÃ¼revlerin hesaplandÄ±ÄŸÄ± Sobel filtresinin boyutu.\n"
    "â€¢ k DeÄŸeri: Harris denkleminde kullanÄ±lan serbest parametre (genellikle 0.04 - 0.06 arasÄ±).\n\n"
    "ğŸŸ¥ YÃ¼ksek cevap veren alanlar kÄ±rmÄ±zÄ± ile iÅŸaretlenir, bu alanlar kÃ¶ÅŸe iÃ§eriyor olabilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Harris Corner Detection Parameters\n\n"
    "â€¢ Block Size: Neighborhood size considered for corner detection around each pixel.\n"
    "â€¢ Sobel Kernel Size: Aperture size for the Sobel derivative.\n"
    "â€¢ k Value: Harris detector free parameter, typically between 0.04 and 0.06.\n\n"
    "ğŸŸ¥ Areas with high corner response are marked in red, indicating potential corners."
)


    def create_widgets(self):
        # Entry for block size (neighborhood size)
        tk.Label(self.frame, text="Block Size:").grid(row=1, column=0, padx=2, pady=2)
        self.block_size_entry = tk.Entry(self.frame)
        self.block_size_entry.grid(row=1, column=1, padx=2, pady=2)

        # Entry for ksize (aperture parameter of Sobel)
        tk.Label(self.frame, text="Sobel Kernel Size:").grid(row=2, column=0, padx=2, pady=2)
        self.ksize_entry = tk.Entry(self.frame)
        self.ksize_entry.grid(row=2, column=1, padx=2, pady=2)

        # Entry for Harris detector free parameter k
        tk.Label(self.frame, text="Harris k value (e.g., 0.04):").grid(row=3, column=0, padx=2, pady=2)
        self.k_entry = tk.Entry(self.frame)
        self.k_entry.grid(row=3, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= CornerHarrisFrame.info_text)

    def apply(self, img):
        block_size = int(self.block_size_entry.get())
        ksize = int(self.ksize_entry.get())
        k = float(self.k_entry.get())

        # Convert image to grayscale if not already
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Convert grayscale to float32 as required by cornerHarris
        gray = np.float32(gray)

        # Apply Harris corner detection
        dst = cv2.cornerHarris(gray, block_size, ksize, k)

        # Dilate result for marking the corners (visual enhancement)
        dst = cv2.dilate(dst, None)

        # Create a copy of original image for marking corners
        result_img = img.copy()

        # Threshold to mark strong corners in red
        result_img[dst > 0.01 * dst.max()] = [0, 0, 255]

        return result_img

class GoodFeaturesToTrackFrame(ProcessFrameBase):
    name = "Shi-Tomasi Corner Detection"
    info_text = (
    "ğŸ“Œ KÃ¶ÅŸe AlgÄ±lama: goodFeaturesToTrack\n\n"
    "â€¢ Max Corners: AlgÄ±lanacak maksimum kÃ¶ÅŸe sayÄ±sÄ±.\n"
    "â€¢ Quality Level: AlgÄ±lanan kÃ¶ÅŸelerin minimum kalite eÅŸiÄŸi (0 ile 1 arasÄ±nda).\n"
    "â€¢ Min Distance: AlgÄ±lanan kÃ¶ÅŸeler arasÄ±ndaki minimum mesafe (piksel cinsinden).\n\n"
    "ğŸŸ¢ AlgÄ±lanan kÃ¶ÅŸeler yeÅŸil dairelerle gÃ¶sterilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Corner Detection: goodFeaturesToTrack\n\n"
    "â€¢ Max Corners: Maximum number of corners to detect.\n"
    "â€¢ Quality Level: Minimum quality threshold for corners (between 0 and 1).\n"
    "â€¢ Min Distance: Minimum Euclidean distance between detected corners.\n\n"
    "ğŸŸ¢ Detected corners are drawn as green circles."
)


    def create_widgets(self):
        # Entry for maxCorners (maximum number of corners to return)
        tk.Label(self.frame, text="Max Corners:").grid(row=1, column=0, padx=2, pady=2)
        self.max_corners_entry = tk.Entry(self.frame)
        self.max_corners_entry.grid(row=1, column=1, padx=2, pady=2)

        # Entry for qualityLevel (minimum accepted quality of corners)
        tk.Label(self.frame, text="Quality Level (0 to 1):").grid(row=2, column=0, padx=2, pady=2)
        self.quality_level_entry = tk.Entry(self.frame)
        self.quality_level_entry.grid(row=2, column=1, padx=2, pady=2)

        # Entry for minDistance (minimum possible Euclidean distance between corners)
        tk.Label(self.frame, text="Min Distance:").grid(row=3, column=0, padx=2, pady=2)
        self.min_distance_entry = tk.Entry(self.frame)
        self.min_distance_entry.grid(row=3, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= GoodFeaturesToTrackFrame.info_text)

    def apply(self, img):
        max_corners = int(self.max_corners_entry.get())
        quality_level = float(self.quality_level_entry.get())
        min_distance = float(self.min_distance_entry.get())

        # Convert to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Detect good features to track
        corners = cv2.goodFeaturesToTrack(gray, max_corners, quality_level, min_distance)

        # Copy image to draw results
        result_img = img.copy()

        # Draw detected corners
        if corners is not None:
            for corner in corners:
                x, y = corner.ravel()
                cv2.circle(result_img, (int(x), int(y)), 4, (0, 255, 0), -1)

        return result_img

class AdaptiveThresholdFrame(ProcessFrameBase):
    name = "Adaptive Thresholding"
    info_text = (
    "ğŸ“Œ Adaptif EÅŸikleme: adaptiveThreshold\n\n"
    "â€¢ Max Value: EÅŸik Ã¼stÃ¼ndeki piksellere verilecek maksimum deÄŸer.\n"
    "â€¢ Adaptive Method: Yerel ortalama (Mean) veya Gauss aÄŸÄ±rlÄ±klÄ± ortalama (Gaussian).\n"
    "â€¢ Threshold Type: Binary (beyaz-siyah) ya da Binary Inverted (siyah-beyaz).\n"
    "â€¢ Block Size: Yerel eÅŸikleme iÃ§in pencere boyutu (tek sayÄ± ve >1 olmalÄ±).\n"
    "â€¢ C: Ortalama deÄŸerden Ã§Ä±karÄ±lacak sabit.\n\n"
    "ğŸ“„ Bu iÅŸlem yalnÄ±zca gri seviye gÃ¶rÃ¼ntÃ¼lerde Ã§alÄ±ÅŸÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Adaptive Thresholding: adaptiveThreshold\n\n"
    "â€¢ Max Value: Maximum value to assign to thresholded pixels.\n"
    "â€¢ Adaptive Method: Local Mean or Gaussian-weighted mean.\n"
    "â€¢ Threshold Type: Binary or Binary Inverted.\n"
    "â€¢ Block Size: Size of the local window (odd number > 1).\n"
    "â€¢ C: Constant subtracted from the mean.\n\n"
    "ğŸ“„ Works only on grayscale images."
)


    def create_widgets(self):
        # Entry for max value (maximum intensity value to be assigned to pixels)
        tk.Label(self.frame, text="Max Value:").grid(row=1, column=0, padx=2, pady=2)
        self.max_value_entry = tk.Entry(self.frame)
        self.max_value_entry.grid(row=1, column=1, padx=2, pady=2)

        # Combobox for adaptive method (Mean or Gaussian)
        tk.Label(self.frame, text="Adaptive Method:").grid(row=2, column=0, padx=2, pady=2)
        self.adaptive_method_combobox = ttk.Combobox(self.frame, values=['Mean', 'Gaussian'])
        self.adaptive_method_combobox.grid(row=2, column=1, padx=2, pady=2)

        # Combobox for threshold type (Binary or Binary Inverted)
        tk.Label(self.frame, text="Threshold Type:").grid(row=3, column=0, padx=2, pady=2)
        self.threshold_type_combobox = ttk.Combobox(self.frame, values=['Binary', 'Binary Inverted'])
        self.threshold_type_combobox.grid(row=3, column=1, padx=2, pady=2)

        # Entry for block size (size of local region for thresholding)
        tk.Label(self.frame, text="Block Size (odd > 1):").grid(row=4, column=0, padx=2, pady=2)
        self.block_size_entry = tk.Entry(self.frame)
        self.block_size_entry.grid(row=4, column=1, padx=2, pady=2)

        # Entry for C value (constant to subtract from mean or weighted mean)
        tk.Label(self.frame, text="C (constant):").grid(row=5, column=0, padx=2, pady=2)
        self.c_entry = tk.Entry(self.frame)
        self.c_entry.grid(row=5, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= AdaptiveThresholdFrame.info_text)

    def apply(self, img):
        max_value = int(self.max_value_entry.get())
        adaptive_method = self.adaptive_method_combobox.get()
        threshold_type = self.threshold_type_combobox.get()
        block_size = int(self.block_size_entry.get())
        c = int(self.c_entry.get())

        # Convert to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Apply adaptive thresholding
        if adaptive_method == 'Mean':
            adaptive_method_cv = cv2.ADAPTIVE_THRESH_MEAN_C
        else:
            adaptive_method_cv = cv2.ADAPTIVE_THRESH_GAUSSIAN_C

        if threshold_type == 'Binary':
            threshold_type_cv = cv2.THRESH_BINARY
        else:
            threshold_type_cv = cv2.THRESH_BINARY_INV

        # Apply adaptive thresholding with specified parameters
        thresholded_image = cv2.adaptiveThreshold(gray, max_value, adaptive_method_cv,
                                                 threshold_type_cv, block_size, c)

        return thresholded_image

class OtsuThresholdFrame(ProcessFrameBase):
    name = "Otsu Thresholding"
    info_text = (
    "ğŸ“Œ Otsu EÅŸikleme: cv2.threshold + THRESH_OTSU\n\n"
    "â€¢ Max Value: EÅŸik Ã¼stÃ¼ piksellere atanacak maksimum deÄŸer.\n"
    "â€¢ Threshold Type: Binary (beyaz-siyah) ya da Binary Inverted (siyah-beyaz).\n\n"
    "ğŸ“„ Otsu yÃ¶ntemi, ideal eÅŸiÄŸi otomatik olarak belirler.\n"
    "ğŸ“„ Sadece gri seviye gÃ¶rÃ¼ntÃ¼lerle Ã§alÄ±ÅŸÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Otsu Thresholding: cv2.threshold + THRESH_OTSU\n\n"
    "â€¢ Max Value: Maximum value to assign to thresholded pixels.\n"
    "â€¢ Threshold Type: Binary or Binary Inverted.\n\n"
    "ğŸ“„ Otsu's method automatically computes the optimal threshold.\n"
    "ğŸ“„ Works only on grayscale images."
)


    def create_widgets(self):
        
        tk.Label(self.frame, text="OTSU Threshold:").grid(row=1, column=0, padx=2, pady=2)
        self.otsu_threshold_label = tk.Label(self.frame)
        self.otsu_threshold_label.grid(row=1, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= OtsuThresholdFrame.info_text)
        
    def apply(self, img):
        # Griye Ã§evir (gerekiyorsa)
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Otsu'nun yÃ¶ntemini uygula, yalnÄ±zca eÅŸik deÄŸeri dÃ¶ndÃ¼rÃ¼lÃ¼r
        otsu_thresh_value, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        return int(otsu_thresh_value)
    
    def update_result(self, img):
        threshold = self.apply(img)
        self.otsu_threshold_label.config(text=str(threshold))
    
#! Needed update for contours    
class FindContoursFrame(ProcessFrameBase):
    name = "Find Contours"
    info_text = (
    "ğŸ“Œ Kenar Bulma (FindContours): cv2.findContours\n\n"
    "â€¢ Retrieval Mode:\n"
    "   - RETR_EXTERNAL: Sadece dÄ±ÅŸ konturlarÄ± bulur.\n"
    "   - RETR_LIST: TÃ¼m konturlarÄ± dÃ¼z bir liste olarak verir.\n"
    "   - RETR_TREE: KonturlarÄ±n hiyerarÅŸisini verir.\n\n"
    "â€¢ Approximation Method:\n"
    "   - CHAIN_APPROX_SIMPLE: Gereksiz noktalarÄ± atar (daha hafif).\n"
    "   - CHAIN_APPROX_NONE: TÃ¼m noktalarÄ± dÃ¶ndÃ¼rÃ¼r.\n\n"
    "ğŸ“„ GiriÅŸ gÃ¶rseli griye Ã§evrilir ve ardÄ±ndan ikili eÅŸikleme uygulanÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Contour Detection (FindContours): cv2.findContours\n\n"
    "â€¢ Retrieval Mode:\n"
    "   - RETR_EXTERNAL: Retrieves only external contours.\n"
    "   - RETR_LIST: Retrieves all contours without hierarchy.\n"
    "   - RETR_TREE: Retrieves all contours and reconstructs hierarchy.\n\n"
    "â€¢ Approximation Method:\n"
    "   - CHAIN_APPROX_SIMPLE: Compresses segments to save memory.\n"
    "   - CHAIN_APPROX_NONE: Stores all contour points.\n\n"
    "ğŸ“„ Input image is converted to grayscale and thresholded to binary."
)

    def create_widgets(self):
        # Combobox for contour retrieval mode (e.g., external or all)
        tk.Label(self.frame, text="Retrieval Mode:").grid(row=1, column=0, padx=2, pady=2)
        self.retrieval_mode_combobox = ttk.Combobox(self.frame, values=['RETR_EXTERNAL', 'RETR_LIST', 'RETR_TREE'])
        self.retrieval_mode_combobox.grid(row=1, column=1, padx=2, pady=2)

        # Combobox for contour approximation method (e.g., simple or accurate)
        tk.Label(self.frame, text="Approximation Method:").grid(row=2, column=0, padx=2, pady=2)
        self.approximation_method_combobox = ttk.Combobox(self.frame, values=['CHAIN_APPROX_SIMPLE', 'CHAIN_APPROX_NONE'])
        self.approximation_method_combobox.grid(row=2, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Color:").grid(row=3, column=0, padx=2, pady=2)
        self.color_combobox = ttk.Combobox(self.frame, values=["Red", "Green", "Blue"])
        self.color_combobox.grid(row=3, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= FindContoursFrame.info_text)

    def apply(self, img):
        # Get user selections for retrieval mode and approximation method
        retrieval_mode = self.retrieval_mode_combobox.get()
        approximation_method = self.approximation_method_combobox.get()
        color = self.color_combobox.get()
        
        colors = {
            "Blue": (255, 0, 0),
            "Green": (0, 255, 0),
            "Red": (0, 0, 255)
            }
        
        # Convert to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Apply binary thresholding to create a binary image for contour detection
        # _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

        # Convert user input into OpenCV constants
        retrieval_mode_cv = getattr(cv2, retrieval_mode)
        approximation_method_cv = getattr(cv2, approximation_method)

        # Find contours in the binary image
        contours, hierarchy = cv2.findContours(gray, retrieval_mode_cv, approximation_method_cv)

        # Draw the contours on the original image
        result_img = img.copy()
        cv2.drawContours(result_img, contours, -1, colors[color], 2)

        return result_img    

class DrawContoursFrame(ProcessFrameBase):
    name = "Draw Contours"
    info_text = (
    "ğŸ“Œ KonturlarÄ± Ã‡izme (DrawContours): cv2.drawContours\n\n"
    "â€¢ Kontur KalÄ±nlÄ±ÄŸÄ±:\n"
    "   - Kontur Ã§izgilerinin kalÄ±nlÄ±ÄŸÄ±nÄ± belirtir.\n\n"
    "â€¢ Kontur Rengi:\n"
    "   - SeÃ§ilen renge gÃ¶re konturlar Ã§izilir (YeÅŸil, KÄ±rmÄ±zÄ±, Mavi).\n\n"
    "ğŸ“„ GÃ¶rsel Ã¶nce gri tonlamaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r, ardÄ±ndan ikili eÅŸikleme uygulanarak konturlar bulunur.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Drawing Contours (DrawContours): cv2.drawContours\n\n"
    "â€¢ Contour Thickness:\n"
    "   - Specifies the thickness of contour lines.\n\n"
    "â€¢ Contour Color:\n"
    "   - Contours are drawn in the selected color (Green, Red, Blue).\n\n"
    "ğŸ“„ The image is first converted to grayscale, followed by binary thresholding to detect contours."
)


    def create_widgets(self):
        # Entry for contour thickness (thickness of contour lines)
        tk.Label(self.frame, text="Contour Thickness:").grid(row=1, column=0, padx=2, pady=2)
        self.thickness_entry = tk.Entry(self.frame)
        self.thickness_entry.grid(row=1, column=1, padx=2, pady=2)

        tk.Label(self.frame, text="Color:").grid(row=3, column=0, padx=2, pady=2)
        self.color_combobox = ttk.Combobox(self.frame, values=["Red", "Green", "Blue"])
        self.color_combobox.grid(row=3, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= DrawContoursFrame.info_text)

    def apply(self, img):
        # Get user input for thickness and color
        thickness = int(self.thickness_entry.get())
        color = self.color_combobox.get()

        colors = {
            "Blue": (255, 0, 0),
            "Green": (0, 255, 0),
            "Red": (0, 0, 255)
            }

        # Convert to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Find contours
        contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Draw the contours on the original image
        result_img = img.copy()
        cv2.drawContours(result_img, contours, -1, colors[color], thickness)

        return result_img 
#? Del canny side of houghlines    
class HoughLinesFrame(ProcessFrameBase):
    name = "Hough Line Transform"
    info_text = (
    "ğŸ“Œ Hough DoÄŸrusu DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (HoughLines): cv2.HoughLines\n\n"
    "â€¢ Rho (Mesafe Ã‡Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼):\n"
    "   - Ã‡izgilerin depolandÄ±ÄŸÄ± Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, genellikle piksel cinsindendir.\n\n"
    "â€¢ Theta (AÃ§Ä± Ã‡Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼):\n"
    "   - AÃ§Ä± Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼, genellikle radian cinsindendir.\n\n"
    "â€¢ Threshold (EÅŸik DeÄŸeri):\n"
    "   - AlgÄ±lanan Ã§izgilerin geÃ§mesi gereken minimum puan sayÄ±sÄ±nÄ± belirtir.\n\n"
    "ğŸ“„ GiriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼ mutlaka gri seviyeli olmalÄ± ve canny edge detector gÃ¶rÃ¼ntÃ¼sÃ¼ olmalÄ±.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Hough Line Transform (HoughLines): cv2.HoughLines\n\n"
    "â€¢ Rho (Distance Resolution):\n"
    "   - Specifies the resolution of the accumulator, typically in pixels.\n\n"
    "â€¢ Theta (Angle Resolution):\n"
    "   - Specifies the angle resolution, usually in radians.\n\n"
    "â€¢ Threshold:\n"
    "   - Defines the minimum number of points required to detect a line.\n\n"
    "ğŸ“„ The input image must be grayscale and must be a canny edge detector image."
)


    def create_widgets(self):
        # Entry for rho (distance resolution of the accumulator in pixels)
        tk.Label(self.frame, text="Rho (Distance Resolution):").grid(row=1, column=0, padx=2, pady=2)
        self.rho_entry = tk.Entry(self.frame)
        self.rho_entry.grid(row=1, column=1, padx=2, pady=2)

        # Entry for theta (angle resolution of the accumulator in radians)
        tk.Label(self.frame, text="Theta (Angle Resolution):").grid(row=2, column=0, padx=2, pady=2)
        self.theta_entry = tk.Entry(self.frame)
        self.theta_entry.grid(row=2, column=1, padx=2, pady=2)

        # Entry for threshold (threshold for line detection)
        tk.Label(self.frame, text="Threshold (Line Detection Threshold):").grid(row=3, column=0, padx=2, pady=2)
        self.threshold_entry = tk.Entry(self.frame)
        self.threshold_entry.grid(row=3, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= HoughLinesFrame.info_text)

    def apply(self, img):
        # Get user input for rho, theta, and threshold
        rho = float(self.rho_entry.get())
        theta = float(self.theta_entry.get())
        threshold = int(self.threshold_entry.get())

        # Convert to grayscale if needed
        # if len(img.shape) == 3:
        #     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # else:
        #     gray = img.copy()

        # Apply Canny edge detection to get edges for line detection
        # edges = cv2.Canny(gray, 50, 150, apertureSize=3)

        # Use HoughLines to detect lines
        lines = cv2.HoughLines(img, rho, theta, threshold)

        # Draw the detected lines on the original image
        result_img = img.copy()

        if lines is not None:
            for line in lines:
                rho_line, theta_line = line[0]
                x1 = int(rho_line * np.cos(theta_line) + 1000 * (-np.sin(theta_line)))
                y1 = int(rho_line * np.sin(theta_line) + 1000 * (np.cos(theta_line)))
                x2 = int(rho_line * np.cos(theta_line) - 1000 * (-np.sin(theta_line)))
                y2 = int(rho_line * np.sin(theta_line) - 1000 * (np.cos(theta_line)))
                cv2.line(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)

        return result_img    
    
class DFTFrame(ProcessFrameBase):
    name = "Discrete Fourier Transform (DFT)"
    info_text = (
    "ğŸ“Œ Discrete Fourier Transform (DFT): cv2.dft\n\n"
    "â€¢ DFT Boyutu:\n"
    "   - DFT sonucu iÃ§in gÃ¶rÃ¼ntÃ¼ boyutunu belirler. GÃ¶rÃ¼ntÃ¼ gerekirse sÄ±fÄ±rlarla doldurulur.\n\n"
    "â€¢ SÄ±fÄ±r FrekansÄ±nÄ± Ortaya TaÅŸÄ± (Evet/HayÄ±r):\n"
    "   - EÄŸer seÃ§ilirse, DFT sonucu sÄ±fÄ±r frekans bileÅŸeni spektrumun ortasÄ±na kaydÄ±rÄ±lÄ±r.\n\n"
    "ğŸ“„ GÃ¶rsel Ã¶nce gri tonlamaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r, ardÄ±ndan DFT uygulanÄ±r ve sÄ±fÄ±r frekans bileÅŸeni belirtilen ÅŸekilde kaydÄ±rÄ±lÄ±r. SonuÃ§, genlik deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼p normalleÅŸtirilir ve gÃ¶rÃ¼ntÃ¼lenir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Discrete Fourier Transform (DFT): cv2.dft\n\n"
    "â€¢ DFT Size:\n"
    "   - Specifies the size of the DFT result. The image is padded with zeros if necessary.\n\n"
    "â€¢ Shift Zero Frequency (Yes/No):\n"
    "   - If selected, shifts the zero frequency component to the center of the spectrum.\n\n"
    "ğŸ“„ The image is first converted to grayscale, followed by DFT. The zero frequency component is shifted if required, and the result is converted to magnitude and normalized for display."
)


    def create_widgets(self):
        # Entry for the size of the image (size of the DFT result)
        tk.Label(self.frame, text="DFT Size:").grid(row=1, column=0, padx=2, pady=2)
        self.size_entry = tk.Entry(self.frame)
        self.size_entry.grid(row=1, column=1, padx=2, pady=2)

        # Combobox for selecting whether to shift the zero frequency component
        tk.Label(self.frame, text="Shift Zero Frequency (Yes/No):").grid(row=2, column=0, padx=2, pady=2)
        self.shift_combobox = ttk.Combobox(self.frame, values=['Yes', 'No'])
        self.shift_combobox.grid(row=2, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= DFTFrame.info_text)

    def apply(self, img):
        # Get user input for the size and shift option
        dft_size = int(self.size_entry.get())
        shift_zero_freq = self.shift_combobox.get() == 'Yes'

        # Convert to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Perform Discrete Fourier Transform (DFT)
        # Padding the image to a larger size if necessary
        padded_img = cv2.copyMakeBorder(gray, 0, dft_size - gray.shape[0], 0, dft_size - gray.shape[1], cv2.BORDER_CONSTANT, value=0)
        
        # Perform DFT
        dft = cv2.dft(np.float32(padded_img), flags=cv2.DFT_COMPLEX_OUTPUT)

        # Shift zero frequency to the center of the spectrum if needed
        if shift_zero_freq:
            dft_shift = np.fft.fftshift(dft)
        else:
            dft_shift = dft

        # Convert DFT result to magnitude for display
        magnitude = cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1])

        # Normalize the magnitude image for display
        magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)

        # Convert magnitude to uint8 for display
        result_img = np.uint8(magnitude)

        return result_img    
    
class IDFTFrame(ProcessFrameBase):
    name = "Inverse Discrete Fourier Transform (IDFT)"
    info_text = (
        "ğŸ“Œ Inverse Discrete Fourier Transform (IDFT): cv2.idft\n\n"
        "â€¢ IDFT Boyutu:\n"
        "   - IDFT sonucu iÃ§in gÃ¶rÃ¼ntÃ¼ boyutunu belirler. GÃ¶rÃ¼ntÃ¼ gerekirse sÄ±fÄ±rlarla doldurulur.\n\n"
        "â€¢ SÄ±fÄ±r FrekansÄ±nÄ± Ortaya TaÅŸÄ± (Evet/HayÄ±r):\n"
        "   - EÄŸer seÃ§ilirse, IDFT sonucu sÄ±fÄ±r frekans bileÅŸeni spektrumun ortasÄ±na kaydÄ±rÄ±lÄ±r.\n\n"
        "ğŸ“„ GÃ¶rsel Ã¶nce gri seviyeli olmalÄ± ve Canny kenar algÄ±lama gÃ¶rÃ¼ntÃ¼sÃ¼ gereklidir. \n\n"
        " SonrasÄ±nda DFT iÅŸlemi yapÄ±lÄ±r ve IDFT uygulanarak gÃ¶rsel geri dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. SÄ±fÄ±r frekans bileÅŸeni belirtilen ÅŸekilde kaydÄ±rÄ±lÄ±r. SonuÃ§, genlik deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼p normalleÅŸtirilir ve gÃ¶rÃ¼ntÃ¼lenir.\n\n"
        "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
        "ğŸ“Œ Inverse Discrete Fourier Transform (IDFT): cv2.idft\n\n"
        "â€¢ IDFT Size:\n"
        "   - Specifies the size of the IDFT result. The image is padded with zeros if necessary.\n\n"
        "â€¢ Shift Zero Frequency (Yes/No):\n"
        "   - If selected, shifts the zero frequency component to the center of the spectrum.\n\n"
        "ğŸ“„ The image must first be grayscale and Canny edge detection image is required.\n\n" 
        "Then DFT operation is performed and IDFT is applied to transform the image back. Zero frequency component is shifted as specified. The result is converted to amplitude values, normalized and displayed."
        )

    def create_widgets(self):
        
        # Entry for the size of the image (size of the IDFT result)
        tk.Label(self.frame, text="IDFT Size:").grid(row=1, column=0, padx=2, pady=2)
        self.size_entry = tk.Entry(self.frame)
        self.size_entry.grid(row=1, column=1, padx=2, pady=2)

        # Combobox for selecting whether to shift the zero frequency component
        tk.Label(self.frame, text="Shift Zero Frequency (Yes/No):").grid(row=2, column=0, padx=2, pady=2)
        self.shift_combobox = ttk.Combobox(self.frame, values=['Yes', 'No'])
        self.shift_combobox.grid(row=2, column=1, padx=2, pady=2)
        
        self.info_buttom = ImageButtonApp(self.frame, text= IDFTFrame.info_text)

    def apply(self, img):
        # Get user input for the size and shift option
        idft_size = int(self.size_entry.get())
        shift_zero_freq = self.shift_combobox.get() == 'Yes'

        # Convert to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Apply Canny edge detection to get edges for line detection
        # edges = cv2.Canny(gray, 50, 150, apertureSize=3)

        # Perform DFT
        dft = cv2.dft(np.float32(gray), flags=cv2.DFT_COMPLEX_OUTPUT)

        # Shift zero frequency to the center of the spectrum if needed
        if shift_zero_freq:
            dft_shift = np.fft.fftshift(dft)
        else:
            dft_shift = dft

        # Inverse Discrete Fourier Transform (IDFT)
        idft_shift = np.fft.ifftshift(dft_shift) if shift_zero_freq else dft_shift
        idft = cv2.idft(idft_shift)
        idft_magnitude = cv2.magnitude(idft[:, :, 0], idft[:, :, 1])

        # Normalize the magnitude image for display
        idft_magnitude = cv2.normalize(idft_magnitude, None, 0, 255, cv2.NORM_MINMAX)

        # Convert magnitude to uint8 for display
        result_img = np.uint8(idft_magnitude)

        return result_img    
    
class NumpyFFTFrame(ProcessFrameBase):
    name = "Numpy FFT (Fast Fourier Transform)"
    info_text = (
    "ğŸ“Œ Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (FFT) ve Ters Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (IFFT): np.fft.fft2, np.fft.ifft2\n\n"
    "â€¢ DÃ¶nÃ¼ÅŸÃ¼m Tipi:\n"
    "   - GÃ¶rÃ¼ntÃ¼ye uygulanacak dÃ¶nÃ¼ÅŸÃ¼m tipi seÃ§ilir: FFT (Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼) veya IFFT (Ters Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼).\n\n"
    "ğŸ“„ GÃ¶rsel Ã¶nce gri tonlamaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve float32 formatÄ±na Ã§evrilir. SeÃ§ilen dÃ¶nÃ¼ÅŸÃ¼m tÃ¼rÃ¼ne gÃ¶re iÅŸlem yapÄ±lÄ±r:\n"
    "   - FFT: GÃ¶rÃ¼ntÃ¼ Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼ne uygulanÄ±r ve sÄ±fÄ±r frekansÄ± merkeze kaydÄ±rÄ±lÄ±r. SonuÃ§, genlik spektrumu olarak normalleÅŸtirilip gÃ¶rÃ¼ntÃ¼lenir.\n"
    "   - IFFT: GÃ¶rÃ¼ntÃ¼ Ã¶nce Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼ne sonra ise Ters Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼ne tabi tutulur, bu iÅŸlemle gÃ¶rsel geri dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve normalleÅŸtirilir.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Fourier Transform (FFT) and Inverse Fourier Transform (IFFT): np.fft.fft2, np.fft.ifft2\n\n"
    "â€¢ Transform Type:\n"
    "   - Select the transformation type to apply on the image: FFT (Fourier Transform) or IFFT (Inverse Fourier Transform).\n\n"
    "ğŸ“„ The image is first converted to grayscale and then to float32 format. Based on the selected transform type:\n"
    "   - FFT: The image is transformed using the Fourier Transform, and the zero frequency is shifted to the center. The result is the magnitude spectrum, normalized for display.\n"
    "   - IFFT: The image is first transformed by FFT and then by Inverse FFT to reconstruct the original image, normalized for display."
)


    def create_widgets(self):
        # Combobox for selecting FFT or IFFT
        tk.Label(self.frame, text="Transform Type:").grid(row=1, column=0, padx=2, pady=2)
        self.transform_combobox = ttk.Combobox(self.frame, values=["FFT", "IFFT"])
        self.transform_combobox.grid(row=1, column=1, padx=2, pady=2)

        self.info_buttom = ImageButtonApp(self.frame, text= NumpyFFTFrame.info_text)

    def apply(self, img):
        # Get transform type from combobox
        transform_type = self.transform_combobox.get()

        # Convert image to grayscale if needed
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # Convert image to float32
        gray_float = np.float32(gray)

        # Apply selected transform
        match transform_type:
            case "FFT":
                # Apply FFT and shift zero frequency to center
                fft = np.fft.fft2(gray_float)
                fft_shifted = np.fft.fftshift(fft)

                # Calculate magnitude spectrum and normalize
                magnitude = 20 * np.log(np.abs(fft_shifted) + 1)
                result_img = np.uint8(cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX))
                return result_img

            case "IFFT":
                # Apply FFT and then IFFT (reverse back to spatial domain)
                fft = np.fft.fft2(gray_float)
                img_reconstructed = np.fft.ifft2(fft)
                img_reconstructed = np.abs(img_reconstructed)

                # Normalize result for display
                result_img = np.uint8(cv2.normalize(img_reconstructed, None, 0, 255, cv2.NORM_MINMAX))
                return result_img   

class EqualizeHistFrame(ProcessFrameBase):
    name = "Histogram Equalization"
    info_text = (
    "ğŸ“Œ Histogram EÅŸitleme (EqualizeHist): cv2.equalizeHist\n\n"
    "â€¢ GÃ¶rÃ¼ntÃ¼ Gri Tonlamaya DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r:\n"
    "   - EÄŸer giriÅŸ gÃ¶rseli renkli ise, Ã¶nce gri tonlamaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.\n\n"
    "â€¢ Histogram EÅŸitleme:\n"
    "   - GÃ¶rÃ¼ntÃ¼deki parlaklÄ±k deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± eÅŸitlemek iÃ§in histogram eÅŸitleme uygulanÄ±r.\n"
    "   - Bu iÅŸlem, gÃ¶rselin kontrastÄ±nÄ± artÄ±rarak daha iyi gÃ¶rsel detaylar elde edilmesini saÄŸlar.\n\n"
    "ğŸ“„ Histogram eÅŸitleme, genellikle daha iyi gÃ¶rsel kontrastÄ± elde etmek ve parlaklÄ±k seviyelerini dengelemek iÃ§in kullanÄ±lÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ Histogram Equalization (EqualizeHist): cv2.equalizeHist\n\n"
    "â€¢ Grayscale Conversion:\n"
    "   - If the input image is colored, it is first converted to grayscale.\n\n"
    "â€¢ Histogram Equalization:\n"
    "   - Histogram equalization is applied to equalize the distribution of pixel intensities.\n"
    "   - This enhances the contrast and improves visual details in the image.\n\n"
    "ğŸ“„ Histogram equalization is commonly used to improve image contrast and balance brightness levels."
)

    
    def create_widgets(self):
        self.info_buttom = ImageButtonApp(self.frame, text= EqualizeHistFrame.info_text)
    
    def apply(self, img):
        
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        equalized_img = cv2.equalizeHist(img)
        return equalized_img
    
    def update_result(self, img):
        result = self.apply(img)
        
        plt.figure(figsize=(12,5))
        
        plt.subplot(1, 2, 1)
        plt.title("Original Histogram")
        plt.hist(img.ravel(), bins=256, range=[0,256], color='gray')
        
        plt.subplot(1, 2, 2)
        plt.title("Equalized Histogram")
        plt.hist(result.ravel(), bins=256, range=[0,256], color='black')
        
        plt.tight_layout()   
#! may be malfunctioning
class CLAHEFrame(ProcessFrameBase):
    name = "CLAHE (Contrast Limited Adaptive Histogram Equalization)"
    info_text = (
    "ğŸ“Œ CLAHE (Contrast Limited Adaptive Histogram Equalization): cv2.createCLAHE\n\n"
    "â€¢ Clip Limit:\n"
    "   - Kontrast sÄ±nÄ±rlamasÄ±nÄ±n derecesini belirtir. YÃ¼ksek deÄŸerler daha keskin kontrastlar saÄŸlar.\n\n"
    "â€¢ Tile Grid Size:\n"
    "   - EÅŸitleme iÅŸlemi iÃ§in kullanÄ±lan bÃ¶lgesel Ä±zgaranÄ±n boyutunu belirtir. KÃ¼Ã§Ã¼k Ä±zgaralar daha ayrÄ±ntÄ±lÄ± sonuÃ§lar verir.\n\n"
    "ğŸ“„ CLAHE, Ã¶zellikle aydÄ±nlatma koÅŸullarÄ±nÄ±n dÃ¼zensiz olduÄŸu gÃ¶rÃ¼ntÃ¼lerde kontrastÄ± artÄ±rmak iÃ§in kullanÄ±lÄ±r.\n\n"
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n\n"
    "ğŸ“Œ CLAHE (Contrast Limited Adaptive Histogram Equalization): cv2.createCLAHE\n\n"
    "â€¢ Clip Limit:\n"
    "   - Specifies the contrast limiting factor. Higher values produce sharper contrasts.\n\n"
    "â€¢ Tile Grid Size:\n"
    "   - Defines the size of the grid for local histogram equalization. Smaller grid sizes result in more detailed equalization.\n\n"
    "ğŸ“„ CLAHE is commonly used to improve contrast in images with uneven lighting conditions."
)

    
    def create_widgets(self):
        self.clip_limit = tk.DoubleVar(value=2.0)
        self.tile_grid_size = tk.IntVar(value=8)
        
        self.info_buttom = ImageButtonApp(self.frame, text= CLAHEFrame.info_text)
        
        tk.Label(self.frame, text="Clip Limit:").grid(row=1, column=0, padx=2, pady=2)
        tk.Scale(self.frame, from_=1.0, to=16.0, resolution=0.1,
                variable=self.clip_limit, orient="horizontal").grid(row=1, column=1, padx=2, pady=2)
        
        tk.Label(self.frame, text="Tile Grid Size:").grid(row=2, column=0, padx=2, pady=2)
        tk.Scale(self.frame, from_=1, to=32, variable=self.tile_grid_size,
                orient="horizontal").grid(row=2, column=1, padx=2, pady=2)
    
    def apply(self, img):
        # Convert color image to LAB color space if needed
        is_color = len(img.shape) == 3 and img.shape[2] == 3
        
        # Create CLAHE object
        clahe = cv2.createCLAHE(
            clipLimit=self.clip_limit.get(),
            tileGridSize=(self.tile_grid_size.get(), self.tile_grid_size.get())
        )
        
        if is_color:
            # Convert BGR to LAB
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            # Apply CLAHE to the L channel
            l_clahe = clahe.apply(l)
            # Merge and convert back to BGR
            lab_clahe = cv2.merge((l_clahe, a, b))
            result = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)
        else:
            # For grayscale image, apply CLAHE directly
            result = clahe.apply(img)
        
        return result
    
    def update_result(self, img):
        result = self.apply(img)
        
        # Show input and output images side by side
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        plt.title("Original Image")
        if len(img.shape) == 2:
            plt.imshow(img, cmap='gray')
        else:
            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.title("CLAHE Result")
        if len(result.shape) == 2:
            plt.imshow(result, cmap='gray')
        else:
            plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        
        plt.tight_layout()